{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Radar plots\n",
    "\n",
    "In this lesson, we go step-by-step through the process of making player radars\n",
    "for a striker. We calculate the following metrics directly from\n",
    "a count of actions in the Wyscout event data,\n",
    "\n",
    "- Non-penalty goals\n",
    "- Assists\n",
    "- Key passes\n",
    "- Smart passes\n",
    "- Ariel duels won\n",
    "- Ground attacking duels won\n",
    "\n",
    "We add tho these our own calculations of,\n",
    "\n",
    "- non-penalty expected goals.\n",
    "- passes ending in final third\n",
    "- receptions in final third.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# statistical fitting of models\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "#opening data\n",
    "import os\n",
    "import pathlib\n",
    "import warnings \n",
    "#used for plots\n",
    "from scipy import stats\n",
    "from mplsoccer import PyPizza, FontManager\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening data\n",
    "For this task we will use Wyscout data. We open it, save in the dataframe\n",
    "*train*. To avoid potential errors, we keep\n",
    "only the data for which the beginning and end of an action was registered. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\aleex\\\\Data Science Projects\\\\Formation\\\\M_Soccermatics - UPPSALA\\\\3_Scouting\\\\data\\\\Wyscout\\\\events_England_1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19016/3710464790.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'events_England_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.json'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Wyscout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\aleex\\\\Data Science Projects\\\\Formation\\\\M_Soccermatics - UPPSALA\\\\3_Scouting\\\\data\\\\Wyscout\\\\events_England_1.json'"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "for i in range(13):\n",
    "    file_name = 'events_England_' + str(i+1) + '.json'\n",
    "    path = os.path.join(str(pathlib.Path().resolve().parents[0]), 'data', 'Wyscout', file_name)\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    train = pd.concat([train, pd.DataFrame(data)])\n",
    "#potential data collection error handling\n",
    "train = train.loc[train.apply (lambda x: len(x.positions) == 2, axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating xG value\n",
    "As one of the pieces of our radar plot we want to use the Expected Goals statistic. We build 2 different models \n",
    "for headers and shots with leg. Then, the statistic is calculated.\n",
    "If we want to use non-penalty xG,\n",
    "we can set the npxG value of function to True.\n",
    "We calculate the cummulative xG for all players and return the dataframe\n",
    "only with *playerId* and this value.\n",
    "\n",
    "This uses the same method as in lesson 2 to caluclate xG\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calulatexG(df, npxG):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "        dataframe with Wyscout event data.\n",
    "    npxG : boolean\n",
    "        True if xG should not include penalties, False elsewhere.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xG_sum: dataframe\n",
    "        dataframe with sum of Expected Goals for players during the season.\n",
    "\n",
    "    \"\"\"\n",
    "    #very basic xG model based on \n",
    "    shots = df.loc[df[\"eventName\"] == \"Shot\"].copy()\n",
    "    shots[\"X\"] = shots.positions.apply(lambda cell: (100 - cell[0]['x']) * 105/100)\n",
    "    shots[\"Y\"] = shots.positions.apply(lambda cell: cell[0]['y'] * 68/100)\n",
    "    shots[\"C\"] = shots.positions.apply(lambda cell: abs(cell[0]['y'] - 50) * 68/100)\n",
    "    #calculate distance and angle \n",
    "    shots[\"Distance\"] = np.sqrt(shots[\"X\"]**2 + shots[\"C\"]**2)\n",
    "    shots[\"Angle\"] = np.where(np.arctan(7.32 * shots[\"X\"] / (shots[\"X\"]**2 + shots[\"C\"]**2 - (7.32/2)**2)) > 0, np.arctan(7.32 * shots[\"X\"] /(shots[\"X\"]**2 + shots[\"C\"]**2 - (7.32/2)**2)), np.arctan(7.32 * shots[\"X\"] /(shots[\"X\"]**2 + shots[\"C\"]**2 - (7.32/2)**2)) + np.pi)\n",
    "    #if you ever encounter problems (like you have seen that model treats 0 as 1 and 1 as 0) while modelling - change the dependant variable to object \n",
    "    shots[\"Goal\"] = shots.tags.apply(lambda x: 1 if {'id':101} in x else 0).astype(object)\n",
    "        #headers have id = 403\n",
    "    headers = shots.loc[shots.apply (lambda x:{'id':403} in x.tags, axis = 1)]\n",
    "    non_headers = shots.drop(headers.index)\n",
    "    \n",
    "    headers_model = smf.glm(formula=\"Goal ~ Distance + Angle\" , data=headers, \n",
    "                               family=sm.families.Binomial()).fit()\n",
    "    #non-headers\n",
    "    nonheaders_model = smf.glm(formula=\"Goal ~ Distance + Angle\" , data=non_headers, \n",
    "                               family=sm.families.Binomial()).fit()\n",
    "    #assigning xG\n",
    "    #headers\n",
    "    b_head = headers_model.params\n",
    "    xG = 1/(1+np.exp(b_head[0]+b_head[1]*headers['Distance'] + b_head[2]*headers['Angle'])) \n",
    "    headers = headers.assign(xG = xG)\n",
    "\n",
    "    #non-headers \n",
    "    b_nhead = nonheaders_model.params\n",
    "    xG = 1/(1+np.exp(b_nhead[0]+b_nhead[1]*non_headers['Distance'] + b_nhead[2]*non_headers['Angle'])) \n",
    "    non_headers = non_headers.assign(xG = xG)\n",
    "    \n",
    "    if npxG == False:\n",
    "        #find pens\n",
    "        penalties = df.loc[df[\"subEventName\"] == \"Penalty\"]\n",
    "        #assign 0.8\n",
    "        penalties = penalties.assign(xG = 0.8)\n",
    "        #concat, group and sum\n",
    "        all_shots_xg = pd.concat([non_headers[[\"playerId\", \"xG\"]], headers[[\"playerId\", \"xG\"]], penalties[[\"playerId\", \"xG\"]]])\n",
    "        xG_sum = all_shots_xg.groupby([\"playerId\"])[\"xG\"].sum().sort_values(ascending = False).reset_index()\n",
    "    else:\n",
    "        #concat, group and sum\n",
    "        all_shots_xg = pd.concat([non_headers[[\"playerId\", \"xG\"]], headers[[\"playerId\", \"xG\"]]]) \n",
    "        all_shots_xg.rename(columns = {\"xG\": \"npxG\"}, inplace = True)\n",
    "        xG_sum = all_shots_xg.groupby([\"playerId\"])[\"npxG\"].sum().sort_values(ascending = False).reset_index()\n",
    "    #group by player and sum \n",
    "    \n",
    "    return xG_sum\n",
    "\n",
    "#making function\n",
    "npxg = calulatexG(train, npxG = True)\n",
    "#investigate structure\n",
    "npxg.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating passes ending in final third and receptions in final third\n",
    "These 2 statistics capture how good a player is in receiving and passing th\n",
    "ball in the final third. These statistics add context to passes. It isn't enough\n",
    "for a striker to be a good passer of the ball he or she should be able to perform well in the final third.\n",
    "\n",
    "To get the information about receptions, the basic idea is that the player who made\n",
    "the next action was the receiver.  We filter successful passes that ended in the final third and get the passes\n",
    "as well as the receiver. As in the last step, we sum them by player and merge these dataframes\n",
    "to return one. Note that we use\n",
    "outer join not to forget a player who made no\n",
    "receptions in the final third, bud did make some passes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FinalThird(df):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "        dataframe with Wyscout event data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    final_third: dataframe\n",
    "        dataframe with number of passes ending in final third and receptions in that area for a player. \n",
    "\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    #need player who had received the ball\n",
    "    df[\"nextPlayerId\"] = df[\"playerId\"].shift(-1)\n",
    "    passes = df.loc[train[\"eventName\"] == \"Pass\"].copy()\n",
    "    #changing coordinates\n",
    "    passes[\"x\"] = passes.positions.apply(lambda cell: (cell[0]['x']) * 105/100)\n",
    "    passes[\"y\"] = passes.positions.apply(lambda cell: (100 - cell[0]['y']) * 68/100)\n",
    "    passes[\"end_x\"] = passes.positions.apply(lambda cell: (cell[1]['x']) * 105/100)\n",
    "    passes[\"end_y\"] = passes.positions.apply(lambda cell: (100 - cell[1]['y']) * 68/100)\n",
    "    \n",
    "    #get accurate passes\n",
    "    accurate_passes = passes.loc[passes.apply (lambda x:{'id':1801} in x.tags, axis = 1)]\n",
    "    #get passes into final third\n",
    "    final_third_passes = accurate_passes.loc[accurate_passes[\"end_x\"] > 2*105/3]\n",
    "    \n",
    "    #passes into final third by player\n",
    "    ftp_player = final_third_passes.groupby([\"playerId\"]).end_x.count().reset_index()\n",
    "    ftp_player.rename(columns = {'end_x':'final_third_passes'}, inplace=True)\n",
    "    \n",
    "    #receptions of accurate passes in the final third\n",
    "    rtp_player = final_third_passes.groupby([\"nextPlayerId\"]).end_x.count().reset_index()\n",
    "    rtp_player.rename(columns = {'end_x':'final_third_receptions', \"nextPlayerId\": \"playerId\"}, inplace=True)\n",
    "    \n",
    "    #outer join not to lose values\n",
    "    final_third = ftp_player.merge(rtp_player, how = \"outer\", on = [\"playerId\"])\n",
    "    return final_third\n",
    "\n",
    "final_third = FinalThird(train)\n",
    "#investigate structure\n",
    "final_third.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating air and ground duels won\n",
    "To our chart we would as well add number of duels won, but want to differentiate between air and attacking ground duels - many of them will be dribbles. \n",
    "The deifinition of \n",
    "Wyscout duel can be found [here](https://dataglossary.wyscout.com/duel/). Both for air duels and attacking ground duels we repeat \n",
    "the next steps - we sum them by player and outer join two dataframes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wonDuels(df):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "        dataframe with Wyscout event data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    duels_won: dataframe\n",
    "        dataframe with number of won air and ground duels for a player \n",
    "\n",
    "    \"\"\"\n",
    "    #find air duels\n",
    "    air_duels = df.loc[df[\"subEventName\"] == \"Air duel\"]\n",
    "    #703 is the id of a won duel\n",
    "    won_air_duels = air_duels.loc[air_duels.apply (lambda x:{'id':703} in x.tags, axis = 1)]\n",
    "    \n",
    "    #group and sum air duels\n",
    "    wad_player =  won_air_duels.groupby([\"playerId\"]).eventId.count().reset_index()\n",
    "    wad_player.rename(columns = {'eventId':'air_duels_won'}, inplace=True)\n",
    "    \n",
    "    #find ground duels won\n",
    "    ground_duels = df.loc[df[\"subEventName\"].isin([\"Ground attacking duel\"])]\n",
    "    won_ground_duels = ground_duels.loc[ground_duels.apply (lambda x:{'id':703} in x.tags, axis = 1)]\n",
    "    \n",
    "    wgd_player =  won_ground_duels.groupby([\"playerId\"]).eventId.count().reset_index()\n",
    "    wgd_player.rename(columns = {'eventId':'ground_duels_won'}, inplace=True)\n",
    "    \n",
    "    #outer join\n",
    "    duels_won = wgd_player.merge(wad_player, how = \"outer\", on = [\"playerId\"])\n",
    "    return duels_won\n",
    "\n",
    "duels = wonDuels(train)\n",
    "#investigate structure\n",
    "duels.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating smart passes\n",
    "Another statistic that we want to add are accurate smart passes. Those are the passes that break the opponent defensive line. \n",
    "The exact deifinition of \n",
    "Wyscout smart pass can be found [here](https://dataglossary.wyscout.com/smart_pass/). Also in this case, we sum smart passes \n",
    "by player.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smartPasses(df):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "        dataframe with Wyscout event data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sp_player: dataframe\n",
    "        dataframe with number of smart passes.\n",
    "\n",
    "    \"\"\"\n",
    "    #get smart passes\n",
    "    smart_passes = df.loc[df[\"subEventName\"] == \"Smart pass\"]\n",
    "    #find accurate\n",
    "    smart_passes_made = smart_passes.loc[smart_passes.apply (lambda x:{'id':1801} in x.tags, axis = 1)]\n",
    "    \n",
    "    #sum by player\n",
    "    sp_player =  smart_passes_made.groupby([\"playerId\"]).eventId.count().reset_index()\n",
    "    sp_player.rename(columns = {'eventId':'smart_passes'}, inplace=True)\n",
    "    \n",
    "    return sp_player\n",
    "\n",
    "smart_passes = smartPasses(train)\n",
    "#investigate structure\n",
    "smart_passes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating smart passes\n",
    "Our radar plots wouldn't be completed without non-penalty goals, assists and key passes. To sum them, we repeat steps previosuly \n",
    "described.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GoalsAssistsKeyPasses(df):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "        dataframe with Wyscout event data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data: dataframe\n",
    "        dataframe with number of (non-penalty) goals, assists and key passes.\n",
    "\n",
    "    \"\"\"\n",
    "    #get goals\n",
    "    shots = df.loc[df[\"subEventName\"] == \"Shot\"]\n",
    "    goals = shots.loc[shots.apply (lambda x:{'id':101} in x.tags, axis = 1)]\n",
    "    #get assists\n",
    "    passes = df.loc[df[\"eventName\"] == \"Pass\"]\n",
    "    assists = passes.loc[passes.apply (lambda x:{'id':301} in x.tags, axis = 1)]\n",
    "    #get key passes\n",
    "    key_passes = passes.loc[passes.apply (lambda x:{'id':302} in x.tags, axis = 1)]\n",
    "    \n",
    "    #goals by player\n",
    "    g_player =  goals.groupby([\"playerId\"]).eventId.count().reset_index()\n",
    "    g_player.rename(columns = {'eventId':'goals'}, inplace=True)\n",
    "    \n",
    "    #assists by player\n",
    "    a_player =  assists.groupby([\"playerId\"]).eventId.count().reset_index()\n",
    "    a_player.rename(columns = {'eventId':'assists'}, inplace=True)\n",
    "    \n",
    "    #key passes by player\n",
    "    kp_player =  key_passes.groupby([\"playerId\"]).eventId.count().reset_index()\n",
    "    kp_player.rename(columns = {'eventId':'key_passes'}, inplace=True)\n",
    "    \n",
    "    data = g_player.merge(a_player, how = \"outer\", on = [\"playerId\"]).merge(kp_player, how = \"outer\", on = [\"playerId\"])\n",
    "    return data\n",
    "\n",
    "gakp = GoalsAssistsKeyPasses(train)\n",
    "#investigate structure \n",
    "gakp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minutes played\n",
    "All data on our plot will be per 90 minutes played. Therefore, we need an information on the number of minutes played\n",
    "throughout the season. To do so, we will use a prepared file that bases on the idea developed by students\n",
    "taking part in course in 2021. Files with miutes per game for players in top 5 leagues can be found\n",
    "[here](https://github.com/soccermatics/Soccermatics/tree/main/course/lessons/minutes_played). After downloading data and saving\n",
    "it in out directory, we open it and store in a dataframe. Then we calculate the sum of miutes played in a season for each player.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(str(pathlib.Path().resolve().parents[0]),\"minutes_played\", 'minutes_played_per_game_England.json')\n",
    "with open(path) as f:\n",
    "    minutes_per_game = json.load(f)\n",
    "minutes_per_game = pd.DataFrame(minutes_per_game)\n",
    "minutes = minutes_per_game.groupby([\"playerId\"]).minutesPlayed.sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary table\n",
    "To make our radar plots we need to first prepare the data with previously calculated statistics. We left join \n",
    "(too keep all the players). Also, we right join minutes, because there may be some players who were on the pitch\n",
    "but didn't make an action. Then, the na observations are filled with zeros (if there was NA scored goals it meant).\n",
    "Moreover, we filter out players who played 400 miutes or less. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = train[\"playerId\"].unique()\n",
    "summary = pd.DataFrame(players, columns = [\"playerId\"])\n",
    "summary = summary.merge(npxg, how = \"left\", on = [\"playerId\"]).merge(final_third, how = \"left\", on = [\"playerId\"]).merge(duels, how = \"left\", on = [\"playerId\"]).merge(smart_passes, how = \"left\", on = [\"playerId\"]).merge(gakp, how = \"left\", on = [\"playerId\"])\n",
    "\n",
    "summary = minutes.merge(summary, how = \"left\", on = [\"playerId\"])\n",
    "summary = summary.fillna(0)\n",
    "summary = summary.loc[summary[\"minutesPlayed\"] > 400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering positions\n",
    "Since we would like to create a plot with attacking values, it is important to keep only forwards (also the player that we will\n",
    "make the plot for is a forward). Therefore, we open the players dataset, we filter out forwards and inner join it with our summary\n",
    "dataframe to keep only Premier League forwards who played more than 400 minutes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(str(pathlib.Path().resolve().parents[0]),\"data\", 'Wyscout', 'players.json')\n",
    "with open(path) as f:\n",
    "    players = json.load(f)\n",
    "player_df = pd.DataFrame(players)\n",
    "forwards = player_df.loc[player_df.apply(lambda x: x.role[\"name\"] == \"Forward\", axis = 1)]\n",
    "forwards.rename(columns = {'wyId':'playerId'}, inplace=True)\n",
    "to_merge = forwards[['playerId', 'shortName']]\n",
    "summary = summary.merge(to_merge, how = \"inner\", on = [\"playerId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating statistics per 90\n",
    "To adjust the data for different number of minutes played, we calculate each statistic we \n",
    "want to plot per 90 minutes player. That means that we multiply it by 90 and divide by\n",
    "the total number of minutes played by player.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_per_90 = pd.DataFrame()\n",
    "summary_per_90[\"shortName\"] = summary[\"shortName\"]\n",
    "for column in summary.columns[2:-1]:\n",
    "    summary_per_90[column + \"_per90\"] = summary.apply(lambda x: x[column]*90/x[\"minutesPlayed\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding values for player\n",
    "For this tutorial we decided to use Mohammed Salah as our player. First, we have to find his \n",
    "*shortName* in the summary database. Then, we filter in the dataframe with data per 90 his statistics.\n",
    "As the next step we store these statistics in a list and calculate in which percentile is the value.\n",
    "Since the\n",
    "distribution of statistics may not be uniform on the interval [minimum value - maximum value], we claim\n",
    "that is better to use them as the size of piece on our radar. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#player to investigate - Mohammed Salah\n",
    "#only his statistics\n",
    "salah = summary_per_90.loc[summary_per_90[\"shortName\"] == \"Mohamed Salah\"]\n",
    "#columns similar together\n",
    "salah = salah[['npxG_per90', \"goals_per90\", \"assists_per90\", \"key_passes_per90\", \"smart_passes_per90\", \"final_third_passes_per90\", \"final_third_receptions_per90\", \"ground_duels_won_per90\", \"air_duels_won_per90\"]]\n",
    "#take only necessary columns - exclude playerId\n",
    "per_90_columns = salah.columns[:]\n",
    "#values to mark on the plot\n",
    "values = [round(salah[column].iloc[0],2) for column in per_90_columns]\n",
    "#percentiles\n",
    "percentiles = [int(stats.percentileofscore(summary_per_90[column], salah[column].iloc[0])) for column in per_90_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making radar charts\n",
    "To plot our radar charts we use mplsoccer and their amazing [tutorials](https://mplsoccer.readthedocs.io/en/latest/gallery/pizza_plots/plot_pizza_basic.html).\n",
    "First we take a list of names that we would like to to describe the statistics. Then, we download fonts using mplsoccer *FontManager* to make our plot look nicer/\n",
    "As the next step we declare a *PyPizza* object which would make a pizza-like radar plot, but in the mplsoccer library there are also \n",
    "[different options](https://mplsoccer.readthedocs.io/en/latest/gallery/radar/index.html) avaliable. Then, we make a pizza plot with our data using *make_pizza* method.\n",
    "to put our data on the plot. Note, as mention before, that the size of our pizza piece is the percentile. Therefore, to put the statistic on the plot,\n",
    "we put the statistic on it. Then, we add title and subtitle to our plot. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of names on plots\n",
    "names = [\"non-penalty Expected Goals\", \"non-penalty Goals\", \"Assists\", \"Key Passes\", \"Smart Passes\", \"Passes Ending in Final Third\", \"Passes Received in Final Third\", \"Offensive Ground Duels Won\", \"Air Duels Won\"]\n",
    "slice_colors = [\"blue\"] * 2 + [\"green\"] * 5 + [\"red\"] * 2\n",
    "text_colors = [\"white\"]*9\n",
    "font_normal = FontManager((\"https://github.com/google/fonts/blob/main/apache/roboto/\"\n",
    "                           \"Roboto%5Bwdth,wght%5D.ttf?raw=true\"))\n",
    "font_bold = FontManager((\"https://github.com/google/fonts/blob/main/apache/robotoslab/\"\n",
    "                         \"RobotoSlab%5Bwght%5D.ttf?raw=true\"))\n",
    "#PIZZA PLOT\n",
    "baker = PyPizza(\n",
    "    params=names,   \n",
    "    min_range = None,\n",
    "    max_range = None,               # list of parameters\n",
    "    straight_line_color=\"#000000\",  # color for straight lines\n",
    "    straight_line_lw=1,             # linewidth for straight lines\n",
    "    last_circle_lw=1,               # linewidth of last circle\n",
    "    other_circle_lw=1,              # linewidth for other circles\n",
    "    other_circle_ls=\"-.\"            # linestyle for other circles\n",
    ")\n",
    "#making pizza for our data\n",
    "fig, ax = baker.make_pizza(\n",
    "    percentiles,              # list of values\n",
    "    figsize=(10, 10),      # adjust figsize according to your need\n",
    "    param_location=110,\n",
    "    slice_colors=slice_colors,\n",
    "    value_colors = text_colors,\n",
    "    value_bck_colors=slice_colors, # where the parameters will be added\n",
    "    kwargs_slices=dict(\n",
    "        facecolor=\"cornflowerblue\", edgecolor=\"#000000\",\n",
    "        zorder=2, linewidth=1\n",
    "    ),                   # values to be used when plotting slices\n",
    "    kwargs_params=dict(\n",
    "        color=\"#000000\", fontsize=12,\n",
    "        fontproperties=font_normal.prop, va=\"center\"\n",
    "    ),                   # values to be used when adding parameter\n",
    "    kwargs_values=dict(\n",
    "        color=\"#000000\", fontsize=12,\n",
    "        fontproperties=font_normal.prop, zorder=3,\n",
    "        bbox=dict(\n",
    "            edgecolor=\"#000000\", facecolor=\"cornflowerblue\",\n",
    "            boxstyle=\"round,pad=0.2\", lw=1\n",
    "        )\n",
    "    )                    # values to be used when adding parameter-values\n",
    ")\n",
    "\n",
    "#putting text\n",
    "texts = baker.get_value_texts()\n",
    "for i, text in enumerate(texts):\n",
    "    text.set_text(str(values[i]))\n",
    "# add title\n",
    "fig.text(\n",
    "    0.515, 0.97, \"Mohammed Salah per 90 - Liverpool FC\", size=18,\n",
    "    ha=\"center\", fontproperties=font_bold.prop, color=\"#000000\"\n",
    ")\n",
    "\n",
    "# add subtitle\n",
    "fig.text(\n",
    "    0.515, 0.942,\n",
    "    \"Premier League | Season 2017-18\",\n",
    "    size=15,\n",
    "    ha=\"center\", fontproperties=font_bold.prop, color=\"#000000\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating possession\n",
    "As the next step we would like to adjust our plot by the player's team ball possesion while they \n",
    "were on the pitch. To do it, for each row of our dataframe with minutes per player per each game \n",
    "we take all the events that were made in this game while the player was on the pitch.\n",
    "We will also use duels, but\n",
    "don't include lost air duels and lost ground defending duels. Why? Possesion is calculated as number of touches by team divided\n",
    "by the number all touches. If a player lost ground defending duel, that means that he could have been dribbled by, so he did not\n",
    "touch the ball. If they lost the air duel, they lost a header. Therefore, we claim that those were mostly events where player may have not\n",
    "touched the ball (or if he did the team did not take control over it). We sum \n",
    "both team passes and these duels and all passes and these duels in this period. We store these values in a \n",
    "dictionary. Then, summing them for each player separately and calculating their ratio, we get \n",
    "the possesion of the ball by player's team while he was on the pitch. As the last step we merge it with our summary dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possesion_dict = {}\n",
    "#for every row in the dataframe\n",
    "for i, row in minutes_per_game.iterrows():\n",
    "    #take player id, team id and match id, minute in and minute out\n",
    "    player_id, team_id, match_id = row[\"playerId\"], row[\"teamId\"], row[\"matchId\"]\n",
    "    #create a key in dictionary if player encounterd first time\n",
    "    if not str(player_id) in possesion_dict.keys():\n",
    "        possesion_dict[str(player_id)] = {'team_passes': 0, 'all_passes' : 0}\n",
    "    min_in = row[\"player_in_min\"]*60\n",
    "    min_out = row[\"player_out_min\"]*60\n",
    "    \n",
    "    #get the dataframe of events from the game\n",
    "    match_df = train.loc[train[\"matchId\"] == match_id].copy()\n",
    "    #add to 2H the highest value of 1H\n",
    "    match_df.loc[match_df[\"matchPeriod\"] == \"2H\", 'eventSec'] = match_df.loc[match_df[\"matchPeriod\"] == \"2H\", 'eventSec'] + match_df.loc[match_df[\"matchPeriod\"] == \"1H\"][\"eventSec\"].iloc[-1]\n",
    "    #take all events from this game and this period\n",
    "    player_in_match_df = match_df.loc[match_df[\"eventSec\"] > min_in].loc[match_df[\"eventSec\"] <= min_out]\n",
    "    #take all passes and won duels as described\n",
    "    all_passes = player_in_match_df.loc[player_in_match_df[\"eventName\"].isin([\"Pass\", \"Duel\"])]\n",
    "    #adjusting for no passes in this period (Tuanzebe)\n",
    "    if len(all_passes) > 0:\n",
    "        #removing lost air duels\n",
    "        no_contact = all_passes.loc[all_passes[\"subEventName\"].isin([\"Air duel\", \"Ground defending duel\",\"Ground loose ball duel\"])].loc[all_passes.apply(lambda x:{'id':701} in x.tags, axis = 1)]\n",
    "        all_passes = all_passes.drop(no_contact.index)\n",
    "    #take team passes \n",
    "    team_passes = all_passes.loc[all_passes[\"teamId\"] == team_id]\n",
    "    #append it {player id: {team passes: sum, all passes : sum}}\n",
    "    possesion_dict[str(player_id)][\"team_passes\"] += len(team_passes)\n",
    "    possesion_dict[str(player_id)][\"all_passes\"] += len(all_passes)\n",
    "\n",
    "#calculate possesion for each player\n",
    "percentage_dict = {key: value[\"team_passes\"]/value[\"all_passes\"] if value[\"all_passes\"] > 0 else 0 for key, value in possesion_dict.items()}\n",
    "#create a dataframe\n",
    "percentage_df = pd.DataFrame(percentage_dict.items(), columns = [\"playerId\", \"possesion\"])\n",
    "percentage_df[\"playerId\"] = percentage_df[\"playerId\"].astype(int)\n",
    "#merge it\n",
    "summary = summary.merge(percentage_df, how = \"left\", on = [\"playerId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting data for possession\n",
    "Since we would like to adjust our values by possession, we divide the total statistics by the\n",
    "possesion while player was on the pitch during the entire season. To normalize the values per \n",
    "90 minutes player we repeat the multiplication by 90 and division by minutes played.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe only for it\n",
    "summary_adjusted = pd.DataFrame()\n",
    "summary_adjusted[\"shortName\"] = summary[\"shortName\"]\n",
    "#calculate value adjusted\n",
    "for column in summary.columns[2:11]:\n",
    "    summary_adjusted[column + \"_adjusted_per90\"] = summary.apply(lambda x: (x[column]/x[\"possesion\"])*90/x[\"minutesPlayed\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the plot with adjusted data for Mohammed Salah\n",
    "After calculating the values, we repeat the steps by calculating percentiles and plotting radars from \n",
    "making the plot per 90. Note that this time we show the percentile rank on the plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salah_adjusted = summary_adjusted.loc[summary_adjusted[\"shortName\"] == \"Mohamed Salah\"]\n",
    "salah_adjusted = salah_adjusted[['npxG_adjusted_per90', \"goals_adjusted_per90\", \"assists_adjusted_per90\", \"key_passes_adjusted_per90\", \"smart_passes_adjusted_per90\", \"final_third_passes_adjusted_per90\", \"final_third_receptions_adjusted_per90\", \"ground_duels_won_adjusted_per90\", \"air_duels_won_adjusted_per90\"]]\n",
    "#take only necessary columns\n",
    "adjusted_columns = salah_adjusted.columns[:]\n",
    "#values\n",
    "values = [salah_adjusted[column].iloc[0] for column in adjusted_columns]\n",
    "#percentiles\n",
    "percentiles = [int(stats.percentileofscore(summary_adjusted[column], salah_adjusted[column].iloc[0])) for column in adjusted_columns]\n",
    "names = names = [\"non-penalty Expected Goals\", \"non-penalty Goals\", \"Assists\", \"Key Passes\", \"Smart Passes\", \"Passes Ending in Final Third\", \"Passes Received in Final Third\", \"Offensive Ground Duels Won\", \"Air Duels Won\"]\n",
    "\n",
    "\n",
    "font_normal = FontManager((\"https://github.com/google/fonts/blob/main/apache/roboto/\"\n",
    "                           \"Roboto%5Bwdth,wght%5D.ttf?raw=true\"))\n",
    "font_italic = FontManager((\"https://github.com/google/fonts/blob/main/apache/roboto/\"\n",
    "                           \"Roboto-Italic%5Bwdth,wght%5D.ttf?raw=true\"))\n",
    "font_bold = FontManager((\"https://github.com/google/fonts/blob/main/apache/robotoslab/\"\n",
    "                         \"RobotoSlab%5Bwght%5D.ttf?raw=true\"))\n",
    "\n",
    "baker = PyPizza(\n",
    "    params=names,                  # list of parameters\n",
    "    straight_line_color=\"#000000\",  # color for straight lines\n",
    "    straight_line_lw=1,             # linewidth for straight lines\n",
    "    last_circle_lw=1,               # linewidth of last circle\n",
    "    other_circle_lw=1,              # linewidth for other circles\n",
    "    other_circle_ls=\"-.\"            # linestyle for other circles\n",
    ")\n",
    "\n",
    "fig, ax = baker.make_pizza(\n",
    "    percentiles,              # list of values\n",
    "    figsize=(10, 10),      # adjust figsize according to your need\n",
    "    param_location=110,\n",
    "    slice_colors=slice_colors,\n",
    "    value_colors = text_colors,\n",
    "    value_bck_colors=slice_colors,\n",
    "    # where the parameters will be added\n",
    "    kwargs_slices=dict(\n",
    "        facecolor=\"cornflowerblue\", edgecolor=\"#000000\",\n",
    "        zorder=2, linewidth=1\n",
    "    ),                   # values to be used when plotting slices\n",
    "    kwargs_params=dict(\n",
    "        color=\"#000000\", fontsize=12,\n",
    "        fontproperties=font_normal.prop, va=\"center\"\n",
    "    ),                   # values to be used when adding parameter\n",
    "    kwargs_values=dict(\n",
    "        color=\"#000000\", fontsize=12,\n",
    "        fontproperties=font_normal.prop, zorder=3,\n",
    "        bbox=dict(\n",
    "            edgecolor=\"#000000\", facecolor=\"cornflowerblue\",\n",
    "            boxstyle=\"round,pad=0.2\", lw=1\n",
    "        )\n",
    "    )                    # values to be used when adding parameter-values\n",
    ")\n",
    "\n",
    "# add title\n",
    "fig.text(\n",
    "    0.515, 0.97, \"Mohammed Salah per 90 (possesion adjusted) - Liverpool FC\", size=18,\n",
    "    ha=\"center\", fontproperties=font_bold.prop, color=\"#000000\"\n",
    ")\n",
    "\n",
    "# add subtitle\n",
    "fig.text(\n",
    "    0.515, 0.942,\n",
    "    \"Percentile Rank vs Premier League Forwards | Season 2017-18\",\n",
    "    size=15,\n",
    "    ha=\"center\", fontproperties=font_bold.prop, color=\"#000000\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
